#!/usr/bin/env python3
"""
H-Netè®­ç»ƒé…ç½®å’Œå¯åŠ¨è„šæœ¬
æä¾›ä¸åŒçš„è®­ç»ƒæ¨¡å¼é€‰æ‹©
"""

import os
import sys
import json
import argparse
from datetime import datetime

def create_training_configs():
    """åˆ›å»ºä¸åŒçš„è®­ç»ƒé…ç½®"""
    
    configs = {
        "quick": {
            "name": "å¿«é€Ÿè®­ç»ƒ (3-5åˆ†é’Ÿ)",
            "d_model": 128,
            "num_stages": 1,
            "encoder_layers": 2,
            "decoder_layers": 2,
            "main_layers": 4,
            "batch_size": 16,
            "max_epochs": 5,
            "learning_rate": 1e-3
        },
        
        "medium": {
            "name": "ä¸­ç­‰è®­ç»ƒ 20è½® (8-12åˆ†é’Ÿ)",
            "d_model": 256,
            "num_stages": 2,
            "encoder_layers": 3,
            "decoder_layers": 3,
            "main_layers": 8,
            "batch_size": 8,
            "max_epochs": 20,
            "learning_rate": 5e-4
        },
        
        "balanced": {
            "name": "å¹³è¡¡è®­ç»ƒ (10-15åˆ†é’Ÿ)",
            "d_model": 256,
            "num_stages": 2,
            "encoder_layers": 3,
            "decoder_layers": 3,
            "main_layers": 8,
            "batch_size": 8,
            "max_epochs": 15,
            "learning_rate": 1e-4
        },
        
        "thorough": {
            "name": "æ·±åº¦è®­ç»ƒ (30-60åˆ†é’Ÿ)",
            "d_model": 512,
            "num_stages": 2,
            "encoder_layers": 4,
            "decoder_layers": 4,
            "main_layers": 12,
            "batch_size": 4,
            "max_epochs": 30,
            "learning_rate": 5e-5
        }
    }
    
    return configs

def save_config(config_name, config_params):
    """ä¿å­˜è®­ç»ƒé…ç½®åˆ°æ–‡ä»¶"""
    config_file = f"training_config_{config_name}.json"
    
    full_config = {
        "config_name": config_name,
        "timestamp": datetime.now().isoformat(),
        **config_params
    }
    
    with open(config_file, 'w') as f:
        json.dump(full_config, f, indent=2)
    
    return config_file

def run_training_with_config(config_name, config_params):
    """ä½¿ç”¨æŒ‡å®šé…ç½®è¿è¡Œè®­ç»ƒ"""
    print(f"\nğŸ¯ å¼€å§‹{config_params['name']}...")
    
    # ä¿å­˜é…ç½®
    config_file = save_config(config_name, config_params)
    print(f"ğŸ“ é…ç½®å·²ä¿å­˜åˆ°: {config_file}")
    
    # åˆ›å»ºè®­ç»ƒè„šæœ¬
    training_script = f"""
#!/usr/bin/env python3
import sys
sys.path.append('.')

from hnet_stock_training import *
import json

# åŠ è½½é…ç½®
with open('{config_file}', 'r') as f:
    saved_config = json.load(f)

# åˆ›å»ºH-Neté…ç½®
config = HNetConfig(
    d_model={config_params['d_model']},
    num_stages={config_params['num_stages']},
    encoder_layers={config_params['encoder_layers']},
    decoder_layers={config_params['decoder_layers']},
    main_layers={config_params['main_layers']},
    chunk_ratios=[4, 3],
    batch_size={config_params['batch_size']},
    learning_rate={config_params['learning_rate']},
    max_epochs={config_params['max_epochs']},
    sequence_length=60,
    prediction_horizon=5
)

# è®­ç»ƒ
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"Using device: {{device}}")

trainer = StockTrainer(config, device)

try:
    train_dataset = StockDataset("stock_data", config, 'train')
    val_dataset = StockDataset("stock_data", config, 'val')
    
    print(f"Train samples: {{len(train_dataset)}}")
    print(f"Val samples: {{len(val_dataset)}}")
    
    trainer.train(train_dataset, val_dataset)
    
except Exception as e:
    print(f"Training error: {{e}}")
    raise
"""
    
    # ä¿å­˜å¹¶è¿è¡Œè®­ç»ƒè„šæœ¬
    script_file = f"run_training_{config_name}.py"
    with open(script_file, 'w') as f:
        f.write(training_script)
    
    print(f"ğŸš€ æ‰§è¡Œè®­ç»ƒè„šæœ¬: {script_file}")
    
    # è¿è¡Œè®­ç»ƒ
    os.system(f"python {script_file}")

def main():
    parser = argparse.ArgumentParser(description='H-Netè‚¡ç¥¨åˆ†ææ¨¡å‹è®­ç»ƒ')
    parser.add_argument('--mode', choices=['quick', 'medium', 'balanced', 'thorough'], 
                       help='è®­ç»ƒæ¨¡å¼')
    parser.add_argument('--interactive', action='store_true', 
                       help='äº¤äº’å¼é€‰æ‹©è®­ç»ƒæ¨¡å¼')
    
    args = parser.parse_args()
    
    configs = create_training_configs()
    
    print("ğŸš€ H-Net è‚¡ç¥¨åˆ†ææ¨¡å‹è®­ç»ƒ")
    print("=" * 50)
    
    if args.interactive or not args.mode:
        # äº¤äº’å¼æ¨¡å¼
        print("\nğŸ“‹ å¯ç”¨çš„è®­ç»ƒæ¨¡å¼:")
        for i, (key, config) in enumerate(configs.items(), 1):
            print(f"  {i}. {key}: {config['name']}")
            print(f"     - æ¨¡å‹å¤§å°: {config['d_model']}ç»´, {config['main_layers']}å±‚")
            print(f"     - è®­ç»ƒè½®æ•°: {config['max_epochs']} epochs")
            print(f"     - æ‰¹æ¬¡å¤§å°: {config['batch_size']}")
            print()
        
        while True:
            try:
                choice = input("è¯·é€‰æ‹©è®­ç»ƒæ¨¡å¼ (1-3) æˆ– q é€€å‡º: ").strip()
                if choice.lower() == 'q':
                    print("âŒ è®­ç»ƒå–æ¶ˆ")
                    sys.exit(0)
                
                choice_idx = int(choice) - 1
                if 0 <= choice_idx < len(configs):
                    mode_key = list(configs.keys())[choice_idx]
                    break
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")
            except ValueError:
                print("âŒ è¯·è¾“å…¥æ•°å­—")
    else:
        mode_key = args.mode
    
    # è¿è¡Œé€‰å®šçš„è®­ç»ƒæ¨¡å¼
    config = configs[mode_key]
    print(f"\nâœ… é€‰æ‹©äº†: {config['name']}")
    
    # ç¡®è®¤å¼€å§‹è®­ç»ƒ
    response = input(f"ç¡®è®¤å¼€å§‹è®­ç»ƒ? (y/N): ").strip().lower()
    if response != 'y':
        print("âŒ è®­ç»ƒå–æ¶ˆ")
        sys.exit(0)
    
    run_training_with_config(mode_key, config)

if __name__ == "__main__":
    main()
