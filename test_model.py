#!/usr/bin/env python3
"""
æµ‹è¯•è®­ç»ƒå¥½çš„H-Netè‚¡ç¥¨åˆ†ææ¨¡å‹
"""

import torch
import numpy as np
import json
import logging
from datetime import datetime

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def load_trained_model(model_path='best_stock_hnet.pth'):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    try:
        from hnet_stock_training import StockHNet, HNetConfig
        
        logger.info(f"åŠ è½½æ¨¡å‹: {model_path}")
        
        # åŠ è½½checkpoint
        checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
        
        # ä»checkpointè·å–é…ç½®
        if 'config' in checkpoint:
            config = checkpoint['config']
        else:
            # ä½¿ç”¨é»˜è®¤å¿«é€Ÿè®­ç»ƒé…ç½®
            config = HNetConfig(
                d_model=128,
                num_stages=1,
                encoder_layers=2,
                decoder_layers=2,
                main_layers=4,
                sequence_length=60,
                prediction_horizon=5
            )
        
        # åˆ›å»ºæ¨¡å‹
        model = StockHNet(config)
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()
        
        logger.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
        logger.info(f"   æ¨¡å‹å‚æ•°: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M")
        logger.info(f"   è®­ç»ƒè½®æ•°: {checkpoint.get('epoch', 'N/A')}")
        logger.info(f"   éªŒè¯æŸå¤±: {checkpoint.get('val_loss', 'N/A'):.4f}")
        
        return model, config
        
    except Exception as e:
        logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None, None

def test_model_inference(model, config):
    """æµ‹è¯•æ¨¡å‹æ¨ç†åŠŸèƒ½"""
    logger.info("ğŸ§ª æµ‹è¯•æ¨¡å‹æ¨ç†...")
    
    batch_size = 2
    seq_len = config.sequence_length
    
    # åˆ›å»ºéšæœºæµ‹è¯•æ•°æ®
    price_data = torch.randn(batch_size, seq_len, config.price_features)
    technical_data = torch.randn(batch_size, seq_len, config.technical_features)
    news_data = torch.randn(batch_size, seq_len, config.news_embed_dim)
    
    try:
        with torch.no_grad():
            predictions, boundary_loss = model(price_data, technical_data, news_data)
        
        logger.info("âœ… æ¨¡å‹æ¨ç†æˆåŠŸ!")
        logger.info(f"   ä»·æ ¼é¢„æµ‹å½¢çŠ¶: {predictions['price'].shape}")
        logger.info(f"   æ³¢åŠ¨ç‡é¢„æµ‹å½¢çŠ¶: {predictions['volatility'].shape}")
        logger.info(f"   æ–¹å‘é¢„æµ‹å½¢çŠ¶: {predictions['direction'].shape}")
        logger.info(f"   è¾¹ç•ŒæŸå¤±: {boundary_loss.item():.4f}")
        
        return True
        
    except Exception as e:
        logger.error(f"æ¨¡å‹æ¨ç†å¤±è´¥: {e}")
        return False

def test_with_real_data(model, config):
    """ä½¿ç”¨çœŸå®æ•°æ®æµ‹è¯•æ¨¡å‹"""
    logger.info("ğŸ“Š ä½¿ç”¨çœŸå®æ•°æ®æµ‹è¯•...")
    
    try:
        from hnet_stock_training import StockDataset
        
        # åŠ è½½æµ‹è¯•æ•°æ®
        test_dataset = StockDataset("stock_data", config, 'test')
        
        if len(test_dataset) == 0:
            logger.warning("æ²¡æœ‰æµ‹è¯•æ•°æ®")
            return False
        
        # è·å–ä¸€ä¸ªæ ·æœ¬
        sample = test_dataset[0]
        
        # æ·»åŠ batchç»´åº¦
        price_data = sample['price'].unsqueeze(0)
        technical_data = sample['technical'].unsqueeze(0)
        news_data = sample['news'].unsqueeze(0)
        targets = sample['targets']
        
        with torch.no_grad():
            predictions, _ = model(price_data, technical_data, news_data)
        
        # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
        logger.info("âœ… çœŸå®æ•°æ®æµ‹è¯•æˆåŠŸ!")
        logger.info(f"   çœŸå®ä»·æ ¼ç›®æ ‡: {targets['price'][:3].numpy()}")
        logger.info(f"   é¢„æµ‹ä»·æ ¼: {predictions['price'][0][:3].numpy()}")
        logger.info(f"   çœŸå®æ–¹å‘: {targets['direction'][:3].numpy()}")
        logger.info(f"   é¢„æµ‹æ–¹å‘æ¦‚ç‡: {torch.softmax(predictions['direction'][0][:3], dim=-1).numpy()}")
        
        return True
        
    except Exception as e:
        logger.error(f"çœŸå®æ•°æ®æµ‹è¯•å¤±è´¥: {e}")
        return False

def evaluate_model_performance(model, config):
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    logger.info("ğŸ“ˆ è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
    
    try:
        from hnet_stock_training import StockDataset
        from torch.utils.data import DataLoader
        
        # åŠ è½½æµ‹è¯•æ•°æ®
        test_dataset = StockDataset("stock_data", config, 'test')
        test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=0)
        
        total_samples = 0
        price_mse = 0
        direction_correct = 0
        
        model.eval()
        with torch.no_grad():
            for batch in test_loader:
                price_data = batch['price']
                technical_data = batch['technical']
                news_data = batch['news']
                targets = batch['targets']
                
                predictions, _ = model(price_data, technical_data, news_data)
                
                # è®¡ç®—æŒ‡æ ‡
                batch_size = price_data.shape[0]
                total_samples += batch_size
                
                # ä»·æ ¼MSE
                price_mse += torch.mean((predictions['price'] - targets['price']) ** 2).item() * batch_size
                
                # æ–¹å‘å‡†ç¡®ç‡
                pred_directions = torch.argmax(predictions['direction'], dim=-1)
                direction_correct += torch.sum(pred_directions == targets['direction']).item()
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        price_mse /= total_samples
        direction_accuracy = direction_correct / (total_samples * config.prediction_horizon)
        
        logger.info("ğŸ“Š æ¨¡å‹æ€§èƒ½è¯„ä¼°ç»“æœ:")
        logger.info(f"   æµ‹è¯•æ ·æœ¬æ•°: {total_samples}")
        logger.info(f"   ä»·æ ¼é¢„æµ‹MSE: {price_mse:.4f}")
        logger.info(f"   æ–¹å‘é¢„æµ‹å‡†ç¡®ç‡: {direction_accuracy:.2%}")
        
        return {
            'price_mse': price_mse,
            'direction_accuracy': direction_accuracy,
            'test_samples': total_samples
        }
        
    except Exception as e:
        logger.error(f"æ€§èƒ½è¯„ä¼°å¤±è´¥: {e}")
        return None

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª H-Net è‚¡ç¥¨åˆ†ææ¨¡å‹æµ‹è¯•")
    print("=" * 50)
    
    # 1. åŠ è½½æ¨¡å‹
    model, config = load_trained_model()
    if model is None:
        print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œé€€å‡ºæµ‹è¯•")
        return
    
    # 2. åŸºç¡€æ¨ç†æµ‹è¯•
    if not test_model_inference(model, config):
        print("âŒ åŸºç¡€æ¨ç†æµ‹è¯•å¤±è´¥")
        return
    
    # 3. çœŸå®æ•°æ®æµ‹è¯•
    if not test_with_real_data(model, config):
        print("âš ï¸  çœŸå®æ•°æ®æµ‹è¯•å¤±è´¥ï¼Œä½†åŸºç¡€åŠŸèƒ½æ­£å¸¸")
    
    # 4. æ€§èƒ½è¯„ä¼°
    performance = evaluate_model_performance(model, config)
    if performance:
        print(f"\nğŸ¯ æ¨¡å‹è®­ç»ƒå®Œæˆ!")
        print(f"   âœ… åŸºç¡€åŠŸèƒ½: æ­£å¸¸")
        print(f"   âœ… æ¨ç†é€Ÿåº¦: æ­£å¸¸")
        print(f"   ğŸ“Š æ€§èƒ½æŒ‡æ ‡:")
        print(f"      - ä»·æ ¼é¢„æµ‹è¯¯å·®: {performance['price_mse']:.4f}")
        print(f"      - æ–¹å‘é¢„æµ‹å‡†ç¡®ç‡: {performance['direction_accuracy']:.2%}")
        
        # åˆ¤æ–­æ¨¡å‹è´¨é‡
        if performance['direction_accuracy'] > 0.4:  # éšæœºæ˜¯33.3%
            print(f"   ğŸ‰ æ¨¡å‹è¡¨ç°è‰¯å¥½!")
        elif performance['direction_accuracy'] > 0.35:
            print(f"   âš¡ æ¨¡å‹è¡¨ç°ä¸€èˆ¬ï¼Œå¯è€ƒè™‘æ›´é•¿æ—¶é—´è®­ç»ƒ")
        else:
            print(f"   âš ï¸  æ¨¡å‹è¡¨ç°è¾ƒå·®ï¼Œå»ºè®®è°ƒæ•´å‚æ•°é‡æ–°è®­ç»ƒ")
    
    print(f"\nğŸ“ è®­ç»ƒäº§å‡ºæ–‡ä»¶:")
    print(f"   - best_stock_hnet.pth: æœ€ä½³è®­ç»ƒæ¨¡å‹")
    print(f"   - training_config_quick.json: è®­ç»ƒé…ç½®")
    
    print(f"\nğŸš€ ä¸‹ä¸€æ­¥å»ºè®®:")
    print(f"   1. å°è¯•æ›´é•¿æ—¶é—´çš„è®­ç»ƒ (balanced æˆ– thorough æ¨¡å¼)")
    print(f"   2. è°ƒæ•´æ¨¡å‹å‚æ•°å’Œå­¦ä¹ ç‡")
    print(f"   3. å¢åŠ æ›´å¤šè®­ç»ƒæ•°æ®")
    print(f"   4. è¿›è¡Œå®æ—¶æ¨ç†æµ‹è¯•")

if __name__ == "__main__":
    main()
