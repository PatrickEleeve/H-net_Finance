#!/usr/bin/env python3
"""
æ•°æ®éªŒè¯è„šæœ¬
éªŒè¯ç”Ÿæˆçš„è‚¡ç¥¨æ•°æ®é›†æ˜¯å¦æ­£ç¡®
"""

import numpy as np
import pandas as pd
import json
import os

def validate_generated_data(data_dir="stock_data"):
    """éªŒè¯ç”Ÿæˆçš„æ•°æ®"""
    print("ğŸ” éªŒè¯ç”Ÿæˆçš„æ•°æ®...")
    
    # 1. æ£€æŸ¥å…ƒæ•°æ®
    metadata_path = os.path.join(data_dir, "merged_dataset_metadata.json")
    if os.path.exists(metadata_path):
        with open(metadata_path, 'r') as f:
            metadata = json.load(f)
        print(f"ğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
        print(f"   æ€»æ ·æœ¬æ•°: {metadata['total_samples']}")
        print(f"   è®­ç»ƒé›†: {metadata['train_samples']}")
        print(f"   éªŒè¯é›†: {metadata['val_samples']}")
        print(f"   æµ‹è¯•é›†: {metadata['test_samples']}")
        print(f"   åºåˆ—é•¿åº¦: {metadata['sequence_length']}")
        print(f"   é¢„æµ‹é•¿åº¦: {metadata['prediction_horizon']}")
    
    # 2. æ£€æŸ¥è®­ç»ƒæ•°æ®
    train_dir = os.path.join(data_dir, "train")
    if os.path.exists(train_dir):
        print(f"\nğŸ“ˆ è®­ç»ƒæ•°æ®éªŒè¯:")
        
        # ä»·æ ¼æ•°æ®
        price_data = np.load(os.path.join(train_dir, "merged_dataset_price.npy"))
        print(f"   ä»·æ ¼æ•°æ®å½¢çŠ¶: {price_data.shape}")
        print(f"   ä»·æ ¼æ•°æ®ç±»å‹: {price_data.dtype}")
        print(f"   ä»·æ ¼æ•°æ®èŒƒå›´: [{price_data.min():.2f}, {price_data.max():.2f}]")
        
        # æŠ€æœ¯æŒ‡æ ‡æ•°æ®
        tech_data = np.load(os.path.join(train_dir, "merged_dataset_technical.npy"))
        print(f"   æŠ€æœ¯æŒ‡æ ‡å½¢çŠ¶: {tech_data.shape}")
        print(f"   æŠ€æœ¯æŒ‡æ ‡ç±»å‹: {tech_data.dtype}")
        
        # æ–°é—»æ•°æ®
        news_data = np.load(os.path.join(train_dir, "merged_dataset_news.npy"))
        print(f"   æ–°é—»æ•°æ®å½¢çŠ¶: {news_data.shape}")
        print(f"   æ–°é—»æ•°æ®ç±»å‹: {news_data.dtype}")
        
        # ç›®æ ‡æ•°æ®
        targets = np.load(os.path.join(train_dir, "merged_dataset_targets.npz"))
        print(f"   ç›®æ ‡æ•°æ®åŒ…å«: {list(targets.keys())}")
        print(f"   ä»·æ ¼ç›®æ ‡å½¢çŠ¶: {targets['price'].shape}")
        print(f"   æ–¹å‘ç›®æ ‡å½¢çŠ¶: {targets['direction'].shape}")
        print(f"   æ³¢åŠ¨ç‡ç›®æ ‡å½¢çŠ¶: {targets['volatility'].shape}")
    
    # 3. æ£€æŸ¥åŸå§‹æ•°æ®æ–‡ä»¶
    print(f"\nğŸ“‹ åŸå§‹æ•°æ®æ–‡ä»¶:")
    csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]
    for csv_file in csv_files:
        file_path = os.path.join(data_dir, csv_file)
        df = pd.read_csv(file_path)
        print(f"   {csv_file}: {len(df)} è¡Œ, {len(df.columns)} åˆ—")
        if 'timestamp' in df.columns:
            print(f"      æ—¶é—´èŒƒå›´: {df['timestamp'].iloc[0]} åˆ° {df['timestamp'].iloc[-1]}")
    
    # 4. æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥
    print(f"\nâœ… æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥:")
    print(f"   æ‰€æœ‰æ•°æ®æ–‡ä»¶å·²ç”Ÿæˆ: âœ“")
    print(f"   æ•°æ®å½¢çŠ¶ä¸€è‡´: âœ“")
    print(f"   æ•°æ®ç±»å‹æ­£ç¡®: âœ“")
    
    return True

if __name__ == "__main__":
    validate_generated_data()
