#!/usr/bin/env python3
"""
ç›´æ¥å¯åŠ¨20ä¸ªepochçš„H-Netè®­ç»ƒ
"""

import os
import sys
import json
from datetime import datetime

def main():
    print("ğŸš€ å¼€å§‹20ä¸ªepochçš„H-Netè®­ç»ƒ")
    print("=" * 50)
    
    # æ£€æŸ¥æ•°æ®æ˜¯å¦å­˜åœ¨
    if not os.path.exists("stock_data/train"):
        print("âŒ æ‰¾ä¸åˆ°è®­ç»ƒæ•°æ®ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®é¢„å¤„ç†è„šæœ¬")
        print("   python hnet_data_preprocess.py")
        return
    
    # åˆ›å»º20epochè®­ç»ƒé…ç½®
    config_20epoch = {
        "config_name": "20epoch",
        "timestamp": datetime.now().isoformat(),
        "name": "20è½®è®­ç»ƒ",
        "d_model": 256,
        "num_stages": 2,
        "encoder_layers": 3,
        "decoder_layers": 3,
        "main_layers": 8,
        "batch_size": 8,
        "max_epochs": 20,
        "learning_rate": 5e-4
    }
    
    # ä¿å­˜é…ç½®
    config_file = "training_config_20epoch.json"
    with open(config_file, 'w') as f:
        json.dump(config_20epoch, f, indent=2)
    
    print(f"ğŸ“ è®­ç»ƒé…ç½®å·²ä¿å­˜åˆ°: {config_file}")
    print(f"ğŸ“Š é…ç½®è¯¦æƒ…:")
    print(f"   - æ¨¡å‹ç»´åº¦: {config_20epoch['d_model']}")
    print(f"   - è®­ç»ƒè½®æ•°: {config_20epoch['max_epochs']}")
    print(f"   - æ‰¹æ¬¡å¤§å°: {config_20epoch['batch_size']}")
    print(f"   - å­¦ä¹ ç‡: {config_20epoch['learning_rate']}")
    print(f"   - é¢„ä¼°æ—¶é—´: 8-12åˆ†é’Ÿ")
    
    # ç¡®è®¤å¼€å§‹è®­ç»ƒ
    response = input(f"\nç¡®è®¤å¼€å§‹20ä¸ªepochçš„è®­ç»ƒ? (y/N): ").strip().lower()
    if response != 'y':
        print("âŒ è®­ç»ƒå–æ¶ˆ")
        return
    
    # åˆ›å»ºè®­ç»ƒè„šæœ¬
    training_script = f'''
#!/usr/bin/env python3
import sys
sys.path.append('.')

from hnet_stock_training import *
import json

# åŠ è½½é…ç½®
with open('{config_file}', 'r') as f:
    saved_config = json.load(f)

print("ğŸ¯ å¼€å§‹20ä¸ªepochè®­ç»ƒ...")
print(f"é…ç½®: {{saved_config['name']}}")

# åˆ›å»ºH-Neté…ç½®
config = HNetConfig(
    d_model={config_20epoch['d_model']},
    num_stages={config_20epoch['num_stages']},
    encoder_layers={config_20epoch['encoder_layers']},
    decoder_layers={config_20epoch['decoder_layers']},
    main_layers={config_20epoch['main_layers']},
    chunk_ratios=[4, 3],
    batch_size={config_20epoch['batch_size']},
    learning_rate={config_20epoch['learning_rate']},
    max_epochs={config_20epoch['max_epochs']},
    sequence_length=60,
    prediction_horizon=5
)

# è®­ç»ƒ
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"ä½¿ç”¨è®¾å¤‡: {{device}}")

trainer = StockTrainer(config, device)

try:
    train_dataset = StockDataset("stock_data", config, 'train')
    val_dataset = StockDataset("stock_data", config, 'val')
    
    print(f"è®­ç»ƒæ ·æœ¬: {{len(train_dataset)}}")
    print(f"éªŒè¯æ ·æœ¬: {{len(val_dataset)}}")
    
    print("\\nå¼€å§‹è®­ç»ƒ...")
    trainer.train(train_dataset, val_dataset)
    
    print("\\nâœ… 20ä¸ªepochè®­ç»ƒå®Œæˆ!")
    print("ğŸ“ æ¨¡å‹å·²ä¿å­˜åˆ°: best_stock_hnet.pth")
    
except Exception as e:
    print(f"âŒ è®­ç»ƒå‡ºé”™: {{e}}")
    raise
'''
    
    # ä¿å­˜å¹¶è¿è¡Œè®­ç»ƒè„šæœ¬
    script_file = "run_training_20epoch.py"
    with open(script_file, 'w') as f:
        f.write(training_script)
    
    print(f"\nğŸš€ å¼€å§‹æ‰§è¡Œ20ä¸ªepochè®­ç»ƒ...")
    print(f"ğŸ“ è®­ç»ƒè„šæœ¬: {script_file}")
    print(f"â±ï¸  é¢„è®¡è€—æ—¶: 8-12åˆ†é’Ÿ")
    print("=" * 50)
    
    # æ‰§è¡Œè®­ç»ƒ
    os.system(f"python {script_file}")
    
    print("\n" + "=" * 50)
    print("ğŸ¯ è®­ç»ƒå®Œæˆ! æ£€æŸ¥ç»“æœ:")
    print("   - best_stock_hnet.pth (è®­ç»ƒå¥½çš„æ¨¡å‹)")
    print("   - training_config_20epoch.json (è®­ç»ƒé…ç½®)")
    print("\nğŸ’¡ è¿è¡Œæµ‹è¯•:")
    print("   python test_model.py")

if __name__ == "__main__":
    main()
