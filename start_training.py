#!/usr/bin/env python3
"""
å¯åŠ¨H-Netè‚¡ç¥¨åˆ†ææ¨¡å‹è®­ç»ƒçš„ç®€æ˜“è„šæœ¬
"""

import os
import sys
import logging
from datetime import datetime

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'training_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        logging.StreamHandler(sys.stdout)
    ]
)

logger = logging.getLogger(__name__)

def check_data_availability():
    """æ£€æŸ¥è®­ç»ƒæ•°æ®æ˜¯å¦å¯ç”¨"""
    data_dir = "stock_data"
    required_splits = ['train', 'val', 'test']
    required_files = ['merged_dataset_price.npy', 'merged_dataset_technical.npy', 
                     'merged_dataset_news.npy', 'merged_dataset_targets.npz']
    
    logger.info("ğŸ” æ£€æŸ¥è®­ç»ƒæ•°æ®...")
    
    if not os.path.exists(data_dir):
        logger.error(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return False
    
    # æ£€æŸ¥å…ƒæ•°æ®æ–‡ä»¶
    metadata_file = os.path.join(data_dir, "merged_dataset_metadata.json")
    if not os.path.exists(metadata_file):
        logger.error("âŒ æ‰¾ä¸åˆ°æ•°æ®é›†å…ƒæ•°æ®æ–‡ä»¶")
        return False
    
    # æ£€æŸ¥è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•æ•°æ®
    for split in required_splits:
        split_dir = os.path.join(data_dir, split)
        if not os.path.exists(split_dir):
            logger.error(f"âŒ æ‰¾ä¸åˆ°{split}æ•°æ®ç›®å½•: {split_dir}")
            return False
        
        for file in required_files:
            file_path = os.path.join(split_dir, file)
            if not os.path.exists(file_path):
                logger.error(f"âŒ æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶: {file_path}")
                return False
    
    logger.info("âœ… æ‰€æœ‰è®­ç»ƒæ•°æ®æ–‡ä»¶æ£€æŸ¥é€šè¿‡")
    return True

def check_dependencies():
    """æ£€æŸ¥å¿…è¦çš„ä¾èµ–æ˜¯å¦å®‰è£…"""
    logger.info("ğŸ” æ£€æŸ¥ä¾èµ–...")
    
    required_packages = [
        'torch', 'numpy', 'pandas', 'tqdm'
    ]
    
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package)
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        logger.error(f"âŒ ç¼ºå°‘å¿…è¦çš„ä¾èµ–åŒ…: {missing_packages}")
        logger.info("è¯·è¿è¡Œ: pip install torch numpy pandas tqdm")
        return False
    
    logger.info("âœ… æ‰€æœ‰ä¾èµ–æ£€æŸ¥é€šè¿‡")
    return True

def estimate_training_time():
    """ä¼°ç®—è®­ç»ƒæ—¶é—´"""
    import json
    
    metadata_file = "stock_data/merged_dataset_metadata.json"
    with open(metadata_file, 'r') as f:
        metadata = json.load(f)
    
    train_samples = metadata['train_samples']
    sequence_length = metadata['sequence_length']
    
    # ç®€å•ä¼°ç®—ï¼ˆåŸºäºç»éªŒï¼‰
    estimated_minutes = (train_samples * sequence_length) / 10000  # ç²—ç•¥ä¼°ç®—
    
    logger.info(f"ğŸ“Š è®­ç»ƒæ•°æ®ç»Ÿè®¡:")
    logger.info(f"   è®­ç»ƒæ ·æœ¬: {train_samples}")
    logger.info(f"   åºåˆ—é•¿åº¦: {sequence_length}")
    logger.info(f"   é¢„æµ‹é•¿åº¦: {metadata['prediction_horizon']}")
    logger.info(f"â±ï¸  é¢„ä¼°è®­ç»ƒæ—¶é—´: {estimated_minutes:.1f} åˆ†é’Ÿ (CPU)")
    
    return estimated_minutes

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ H-Net è‚¡ç¥¨åˆ†ææ¨¡å‹è®­ç»ƒå¯åŠ¨å™¨")
    print("=" * 50)
    
    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        print("\nâŒ ä¾èµ–æ£€æŸ¥å¤±è´¥ï¼Œè¯·å…ˆå®‰è£…å¿…è¦çš„åŒ…")
        sys.exit(1)
    
    # æ£€æŸ¥æ•°æ®
    if not check_data_availability():
        print("\nâŒ æ•°æ®æ£€æŸ¥å¤±è´¥")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œæ•°æ®é¢„å¤„ç†è„šæœ¬ç”Ÿæˆè®­ç»ƒæ•°æ®:")
        print("   python hnet_data_preprocess.py")
        sys.exit(1)
    
    # ä¼°ç®—è®­ç»ƒæ—¶é—´
    estimated_time = estimate_training_time()
    
    # ç”¨æˆ·ç¡®è®¤
    print(f"\nâš ï¸  è®­ç»ƒå‡†å¤‡å°±ç»ªï¼Œé¢„ä¼°éœ€è¦ {estimated_time:.1f} åˆ†é’Ÿ")
    response = input("æ˜¯å¦å¼€å§‹è®­ç»ƒ? (y/N): ").strip().lower()
    
    if response != 'y':
        print("âŒ è®­ç»ƒå–æ¶ˆ")
        sys.exit(0)
    
    print("\nğŸ¯ å¼€å§‹è®­ç»ƒ...")
    
    try:
        # å¯¼å…¥å¹¶è¿è¡Œè®­ç»ƒè„šæœ¬
        from hnet_stock_training import main as train_main
        train_main()
        
    except KeyboardInterrupt:
        logger.info("\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        sys.exit(1)
    
    print("\nâœ… è®­ç»ƒå®Œæˆ!")
    print("ğŸ“ æ£€æŸ¥ä»¥ä¸‹æ–‡ä»¶:")
    print("   - best_stock_hnet.pth (æœ€ä½³æ¨¡å‹)")
    print("   - training_*.log (è®­ç»ƒæ—¥å¿—)")

if __name__ == "__main__":
    main()
